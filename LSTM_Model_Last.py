#%%
import pandas as pd
import numpy as np
import random
import time
from sklearn.preprocessing import MinMaxScaler, RobustScaler  # Sadece MinMaxScaler kullanÄ±lÄ±yor
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, SimpleRNN, Dense, Dropout
from tensorflow.keras.callbacks import EarlyStopping
from tensorflow.keras.regularizers import l2
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
import matplotlib.pyplot as plt
import math
import seaborn as sns

# 1. VERÄ°YÄ° OKU
DATA_PATH = 'birlesik_veri_filled_pchip_monotonic_interpolated.xlsx'
df = pd.read_excel(DATA_PATH)

print("Veri Seti: ",df.shape)
def rep_based_train_test_split(df, test_size=0.2, random_seed=16):

    random.seed(random_seed)
    np.random.seed(random_seed)

    episodes = list(df.groupby(['plant', 'rep']))
    random.shuffle(episodes)

    n_test = int(len(episodes) * test_size)
    test_episodes = episodes[:n_test]
    train_episodes = episodes[n_test:]

    train_df = pd.concat([ep[1] for ep in train_episodes]).reset_index(drop=True)
    test_df = pd.concat([ep[1] for ep in test_episodes]).reset_index(drop=True)

    return train_df, test_df

def create_env_sequences_by_group(df, feature_cols, target_col, time_steps=6, step=1):
    """
    Bitki-replikat bazÄ±nda, zaman sÄ±rasÄ±nÄ± koruyarak kayan pencere (sliding window) ile sequence oluÅŸturur.
    step: pencere kayma adÄ±mÄ± (default=1, sliding window iÃ§in 1 olmalÄ±)
    """
    X_seq, y_seq = [], []

    grouped = df.groupby(['plant', 'rep'])

    for (plant, rep), group in grouped:
        X_env = group[feature_cols].values
        y = group[target_col].values
        n = len(group)

        for i in range(0, n - time_steps + 1, step):
            X_seq.append(X_env[i:i + time_steps])
            y_seq.append(y[i + time_steps - 1])

    return np.array(X_seq), np.array(y_seq)

# 2. GEREKLÄ° KOLONLARI SEÃ‡
feature_cols = [
    'h2o_temp_C',
    'pH',
    'EC',
    'temp_c',
    'relative_humidity_%',
    'dewpoint',
    'days_since_first_measurement',
    'reservoir_size_liters',
    # 'growth_rate',
]
target_col = 'plant_height_cm'
time_steps = 3

plt.hist(df[target_col], bins=30, edgecolor='k')
plt.title('Bitki Boyu DaÄŸÄ±lÄ±mÄ±')
plt.xlabel('Bitki Boyu (cm)')
plt.ylabel('Frekans')
plt.show()

# Tarih kolonunu kaldÄ±r
df = df.drop('date', axis=1)
df = df[df["plant_height_cm"] <= 80]


# 3. TEMÄ°ZLEME VE SIRALAMA
df = df.drop(columns=['harvest_fresh_mass_g', 'harvest_dry_mass_g', 'bay','is_interpolated'])

print(df[feature_cols].head()) 

plt.figure(figsize=(10, 4))
sns.boxplot(x=df[target_col].values)
plt.title("Bitki Boyu - Train Set (Boxplot)")
plt.xlabel("Boy (cm)")
plt.tight_layout()
plt.show()

# EÄŸitim ve test setlerini ayÄ±rma
train_df, test_df = rep_based_train_test_split(df, test_size=0.2, random_seed=13)

# EÄŸitim verisinde pencereleme
X_train_seq, y_train_seq = create_env_sequences_by_group(train_df, feature_cols, target_col, time_steps, step=3)
# Test verisinde pencereleme
X_test_seq, y_test_seq = create_env_sequences_by_group(test_df, feature_cols, target_col, time_steps, step=3)

# X verisini yeniden ÅŸekillendir (2D olacak ÅŸekilde)
n_timesteps = X_train_seq.shape[1]
n_features = X_train_seq.shape[2]

# Ã–lÃ§ekleyiciyi sadece train Ã¼zerinde fit et
scaler_X = RobustScaler()
X_train_flat = X_train_seq.reshape(-1, n_features)
X_test_flat = X_test_seq.reshape(-1, n_features)

scaler_X.fit(X_train_flat)

# DÃ¶nÃ¼ÅŸtÃ¼r ve yeniden orijinal shape'e dÃ¶ndÃ¼r
X_train_scaled = scaler_X.transform(X_train_flat).reshape(-1, n_timesteps, n_features)
X_test_scaled = scaler_X.transform(X_test_flat).reshape(-1, n_timesteps, n_features)

# Y iÃ§in scaler (1D)
scaler_y = RobustScaler()
y_train_scaled = scaler_y.fit_transform(y_train_seq.reshape(-1, 1))
y_test_scaled = scaler_y.transform(y_test_seq.reshape(-1, 1))

#%%
print(f"EÄŸitim sequence sayÄ±sÄ±: {len(X_train_scaled)}")
print(f"Test sequence sayÄ±sÄ±: {len(y_test_scaled)}")
print(f"Sequence ÅŸekli: {X_train_scaled.shape}")
# 8. LSTM MODELÄ° - Adil karÅŸÄ±laÅŸtÄ±rma iÃ§in standart mimari

n_features = X_train_seq.shape[2]
print(f"\nğŸ—ï¸ MODEL MÄ°MARÄ°LERÄ° (Adil karÅŸÄ±laÅŸtÄ±rma iÃ§in aynÄ± nÃ¶ron sayÄ±larÄ±):")
print(f"GiriÅŸ Ã¶zellikleri: {n_features}, Zaman adÄ±mlarÄ±: {time_steps}")

# Standart mimari: 64 nÃ¶ronlu ana katman + 32 dense + Ã§Ä±kÄ±ÅŸ
model = Sequential()
model.add(LSTM(64, input_shape=(time_steps, n_features), activation='tanh', return_sequences=False))
model.add(Dropout(0.2))
model.add(Dense(32, activation='relu'))
model.add(Dense(1))
model.compile(optimizer='adam', loss='mse')

print("LSTM: LSTM(64) â†’ Dropout(0.2) â†’ Dense(32) â†’ Dense(1)")

# 8b. RNN (SimpleRNN) MODELÄ° - AynÄ± mimari
rnn_model = Sequential()
rnn_model.add(SimpleRNN(64, input_shape=(time_steps, n_features), activation='tanh', return_sequences=False))
rnn_model.add(Dropout(0.2))
rnn_model.add(Dense(32, activation='relu'))
rnn_model.add(Dense(1))
rnn_model.compile(optimizer='adam', loss='mse')

print("RNN:  SimpleRNN(64) â†’ Dropout(0.2) â†’ Dense(32) â†’ Dense(1)")

# 8c. ELM MODELÄ° (GeliÅŸtirilmiÅŸ)
from sklearn.base import BaseEstimator, RegressorMixin
from sklearn.utils.validation import check_X_y, check_array, check_is_fitted

class ELMRegressor(BaseEstimator, RegressorMixin):
    """
    Extreme Learning Machine (ELM) Regressor
    
    Parameters:
    -----------
    n_hidden : int, default=100
        Gizli katmandaki nÃ¶ron sayÄ±sÄ±
    activation : function, default=np.tanh
        Aktivasyon fonksiyonu (tanh, relu, sigmoid)
    random_state : int, default=None
        Rastgelelik kontrolÃ¼ iÃ§in seed
    regularization : float, default=None
        L2 regularizasyon katsayÄ±sÄ±
    """
    def __init__(self, n_hidden=100, activation=np.tanh, random_state=None, regularization=None):
        self.n_hidden = n_hidden
        self.activation = activation
        self.random_state = random_state
        self.regularization = regularization
    
    def _get_activation_function(self, name):
        """Aktivasyon fonksiyonunu dÃ¶ndÃ¼rÃ¼r"""
        if name == 'tanh':
            return np.tanh
        elif name == 'sigmoid':
            return lambda x: 1 / (1 + np.exp(-np.clip(x, -250, 250)))
        elif name == 'relu':
            return lambda x: np.maximum(0, x)
        else:
            return self.activation
    
    def fit(self, X, y):
        """ELM modelini eÄŸitir"""
        X, y = check_X_y(X, y)
        rng = np.random.RandomState(self.random_state)
        
        # GiriÅŸ aÄŸÄ±rlÄ±klarÄ± ve bias'larÄ± rastgele baÅŸlat
        self.input_weights_ = rng.normal(size=(X.shape[1], self.n_hidden), scale=1.0)
        self.bias_ = rng.normal(size=(self.n_hidden,), scale=1.0)
        
        # Gizli katman Ã§Ä±ktÄ±sÄ±nÄ± hesapla
        H = self.activation(np.dot(X, self.input_weights_) + self.bias_)
        
        # Ã‡Ä±ktÄ± aÄŸÄ±rlÄ±klarÄ±nÄ± hesapla (Moore-Penrose pseudo-inverse ile)
        if self.regularization is not None:
            # Ridge regularization ile
            self.beta_ = np.linalg.solve(
                H.T @ H + self.regularization * np.eye(H.shape[1]),
                H.T @ y
            )
        else:
            # Standart pseudo-inverse ile
            self.beta_ = np.linalg.pinv(H) @ y
        
        # Model performans bilgilerini sakla
        self.n_features_in_ = X.shape[1]
        self.training_samples_ = X.shape[0]
        
        return self
    
    def predict(self, X):
        """Tahmin yapar"""
        check_is_fitted(self, ["input_weights_", "bias_", "beta_"])
        X = check_array(X)
        
        # Gizli katman Ã§Ä±ktÄ±sÄ±nÄ± hesapla
        H = self.activation(np.dot(X, self.input_weights_) + self.bias_)
        
        # Final tahmin
        return H @ self.beta_
    
    def get_params(self, deep=True):
        """Model parametrelerini dÃ¶ndÃ¼rÃ¼r"""
        return {
            'n_hidden': self.n_hidden,
            'activation': self.activation,
            'random_state': self.random_state,
            'regularization': self.regularization
        }
    
    def set_params(self, **params):
        """Model parametrelerini ayarlar"""
        for key, value in params.items():
            setattr(self, key, value)
        return self

# 9. ERKEN DURDURMA
es_lstm = EarlyStopping(monitor='val_loss', 
                        patience=25,
                        restore_best_weights=True,
                        min_delta=0.001,
                        verbose=1)

es_rnn = EarlyStopping(monitor='val_loss', 
                       patience=25,
                       restore_best_weights=True,
                       min_delta=0.001,
                       verbose=1)


# 10. EÄÄ°TÄ°M (Zaman Ã¶lÃ§Ã¼mÃ¼ ile)

print("ğŸš€ LSTM modeli eÄŸitiliyor...")
start_time = time.time()
history = model.fit(
    X_train_scaled, y_train_scaled,
    validation_split=0.1,
    epochs=200,
    batch_size=32,
    callbacks=[es_lstm],
    verbose=2
)
lstm_training_time = time.time() - start_time
print(f"âœ… LSTM eÄŸitim sÃ¼resi: {lstm_training_time:.2f} saniye")

print("ğŸš€ RNN modeli eÄŸitiliyor...")
start_time = time.time()
rnn_history = rnn_model.fit(
    X_train_scaled, y_train_scaled,
    validation_split=0.1,
    epochs=200,
    batch_size=32,
    callbacks=[es_rnn],
    verbose=2
)
rnn_training_time = time.time() - start_time
print(f"âœ… RNN eÄŸitim sÃ¼resi: {rnn_training_time:.2f} saniye")

# ELM iÃ§in sequence'larÄ± flatten et
X_train_flat = X_train_seq.reshape(X_train_seq.shape[0], -1)  # (samples, timesteps*features)
X_test_flat = X_test_seq.reshape(X_test_seq.shape[0], -1)

# ELM iÃ§in scaled verileri kullan
scaler_elm = RobustScaler()
X_train_flat_scaled = scaler_elm.fit_transform(X_train_flat)
X_test_flat_scaled = scaler_elm.transform(X_test_flat)

# ELM modelini oluÅŸtur ve eÄŸit - Ana katmanlar ile eÅŸleÅŸen nÃ¶ron sayÄ±sÄ±
print("\nELM:  Input â†’ Hidden(64) â†’ Output(1) + Regularization")
print("ğŸš€ ELM modeli eÄŸitiliyor...")
start_time = time.time()
elm_model = ELMRegressor(n_hidden=64, random_state=42, regularization=0.01)  # LSTM/RNN ile aynÄ±
elm_model.fit(X_train_flat_scaled, y_train_seq)  # y_train_seq orijinal deÄŸerleri kullan
elm_training_time = time.time() - start_time
print(f"âœ… ELM eÄŸitim sÃ¼resi: {elm_training_time:.2f} saniye")

# EÄŸitim sÃ¼resi karÅŸÄ±laÅŸtÄ±rmasÄ±
print("\nâ±ï¸ EÄÄ°TÄ°M SÃœRESÄ° KARÅILAÅTIRMASI:")
print(f"LSTM: {lstm_training_time:.2f} saniye")
print(f"RNN:  {rnn_training_time:.2f} saniye")
print(f"ELM:  {elm_training_time:.2f} saniye")

# Model karmaÅŸÄ±klÄ±ÄŸÄ± analizi
lstm_params = model.count_params()
rnn_params = rnn_model.count_params()
elm_params = elm_model.input_weights_.size + elm_model.bias_.size + elm_model.beta_.size

print("\nğŸ”§ MODEL KARMAÅIKLIÄI:")
print(f"LSTM parametreleri: {lstm_params:,}")
print(f"RNN parametreleri:  {rnn_params:,}")
print(f"ELM parametreleri:  {elm_params:,}")

print("\nğŸ—ï¸ DETAYLI MÄ°MARÄ° KARÅILAÅTIRMASI:")
print("="*60)
print(f"{'Model':<8} | {'Ana Katman':<15} | {'Dropout':<8} | {'Dense':<10} | {'Ã‡Ä±kÄ±ÅŸ':<6}")
print("-"*60)
print(f"{'LSTM':<8} | {'LSTM(64)':<15} | {'0.2':<8} | {'Dense(32)':<10} | {'Dense(1)':<6}")
print(f"{'RNN':<8} | {'SimpleRNN(64)':<15} | {'0.2':<8} | {'Dense(32)':<10} | {'Dense(1)':<6}")
print(f"{'ELM':<8} | {'Hidden(64)':<15} | {'Reg=0.01':<8} | {'Direct':<10} | {'Output(1)':<6}")
print("="*60)

# DetaylÄ± parametre analizi
lstm_main_params = 64 * (n_features + 64 + 1) * 4  # LSTM has 4 gates
rnn_main_params = 64 * (n_features + 64 + 1)  # RNN has 1 gate
elm_main_params = n_features * 64 + 64  # Input weights + bias

print(f"\nAna katman parametre sayÄ±sÄ±:")
print(f"  LSTM ana katman: {lstm_main_params:,} (4 kapÄ±li)")  
print(f"  RNN ana katman:  {rnn_main_params:,} (1 kapÄ±li)")
print(f"  ELM gizli katman: {elm_main_params:,}")

print(f"\nModel bÃ¼yÃ¼klÃ¼ÄŸÃ¼ oranlarÄ± (RNN'e gÃ¶re):")
print(f"  LSTM: {lstm_params/rnn_params:.2f}x")
print(f"  RNN:  1.00x (referans)")
print(f"  ELM:  {elm_params/rnn_params:.2f}x")

#%%
# 11. TAHMÄ°N VE TERS Ã–LÃ‡EKLEME
y_pred_scaled = model.predict(X_test_scaled)
y_pred_inv = scaler_y.inverse_transform(y_pred_scaled)

# RNN tahmini
y_rnn_pred_scaled = rnn_model.predict(X_test_scaled)
y_rnn_pred_inv = scaler_y.inverse_transform(y_rnn_pred_scaled)

# ELM tahmini
y_elm_pred = elm_model.predict(X_test_flat_scaled)
y_elm_pred_inv = y_elm_pred  # ELM direkt orijinal deÄŸerlerle eÄŸitildi

Y_test_inv = scaler_y.inverse_transform(y_test_scaled)

# LSTM metrikleri
mae = mean_absolute_error(Y_test_inv, y_pred_inv)
mse = mean_squared_error(Y_test_inv, y_pred_inv)
rmse = math.sqrt(mse)
r_squared = r2_score(Y_test_inv, y_pred_inv)

# RNN metrikleri
mae_rnn = mean_absolute_error(Y_test_inv, y_rnn_pred_inv)
mse_rnn = mean_squared_error(Y_test_inv, y_rnn_pred_inv)
rmse_rnn = math.sqrt(mse_rnn)
r2_rnn = r2_score(Y_test_inv, y_rnn_pred_inv)

# ELM metrikleri
mae_elm = mean_absolute_error(Y_test_inv, y_elm_pred_inv)
mse_elm = mean_squared_error(Y_test_inv, y_elm_pred_inv)
rmse_elm = math.sqrt(mse_elm)
r2_elm = r2_score(Y_test_inv, y_elm_pred_inv)


print("BaÅŸarÄ± Metrikleri:")
print(f"LSTM -> MAE: {mae:.2f}, RMSE: {rmse:.2f}, R2: {r_squared:.2f}")
print(f"RNN  -> MAE: {mae_rnn:.2f}, RMSE: {rmse_rnn:.2f}, R2: {r2_rnn:.2f}")
print(f"ELM  -> MAE: {mae_elm:.2f}, RMSE: {rmse_elm:.2f}, R2: {r2_elm:.2f}")

# 12. MODEL KARÅILAÅTIRMA TABLOSU
import pandas as pd
comparison_df = pd.DataFrame({
    'Model': ['LSTM', 'RNN', 'ELM'],
    'MAE': [mae, mae_rnn, mae_elm],
    'RMSE': [rmse, rmse_rnn, rmse_elm],
    'RÂ²': [r_squared, r2_rnn, r2_elm]
})
print("\nğŸ“Š MODEL KARÅILAÅTIRMA TABLOSU:")
print(comparison_df.round(3))

# En iyi performans gÃ¶steren modeli belirle
best_model_idx = comparison_df['RMSE'].idxmin()
best_model_name = comparison_df.loc[best_model_idx, 'Model']
print(f"\nğŸ† En iyi model (en dÃ¼ÅŸÃ¼k RMSE): {best_model_name}")

# GerÃ§ek model nesnesini seÃ§
if best_model_name == 'LSTM':
    best_model_obj = model
elif best_model_name == 'RNN':
    best_model_obj = rnn_model
else:  # ELM
    best_model_obj = elm_model

# 13. SONUÃ‡ GÃ–RSELLEÅTÄ°RME
plt.figure(figsize=(15, 6))
plt.plot(Y_test_inv[410:468], label='GerÃ§ek', color='black', linewidth=2)
plt.plot(y_pred_inv[410:468], label='LSTM', alpha=0.8)
plt.plot(y_rnn_pred_inv[410:468], label='RNN', alpha=0.8)
plt.plot(y_elm_pred_inv[410:468], label='ELM', alpha=0.8)
plt.legend()
plt.title(f'LSTM, RNN, ELM ile Bitki Boyu Tahmini (Window Size: {time_steps})')
plt.xlabel('Zaman')
plt.ylabel('Bitki Boyu (cm)')
plt.grid(True, alpha=0.3)
plt.tight_layout()
plt.show()

#13.1 Ã–rnek bir bitki Ã¼zerinden tahmin ve gÃ¶rselleÅŸtirme
plt.figure(figsize=(15, 6))
plt.plot(Y_test_inv[410:418], label='GerÃ§ek', color='black', linewidth=2)
plt.plot(y_pred_inv[410:418], label='LSTM', alpha=0.8)
plt.plot(y_rnn_pred_inv[410:418], label='RNN', alpha=0.8)
plt.plot(y_elm_pred_inv[410:418], label='ELM', alpha=0.8)
plt.legend()
plt.title(f'LSTM, RNN, ELM ile Bitki Boyu Tahmini (Window Size: {time_steps})')
plt.xlabel('Zaman')
plt.ylabel('Bitki Boyu (cm)')
plt.grid(True, alpha=0.3)
plt.tight_layout()
plt.show()

#13.1 Ã–rnek bir bitki Ã¼zerinden tahmin ve gÃ¶rselleÅŸtirme
plt.figure(figsize=(15, 6))
plt.plot(Y_test_inv[441:446], label='GerÃ§ek', color='black', linewidth=2)
plt.plot(y_pred_inv[441:446], label='LSTM', alpha=0.8)
plt.plot(y_rnn_pred_inv[441:446], label='RNN', alpha=0.8)
plt.plot(y_elm_pred_inv[441:446], label='ELM', alpha=0.8)
plt.legend()
plt.title(f'LSTM, RNN, ELM ile Bitki Boyu Tahmini (Window Size: {time_steps})')
plt.xlabel('Zaman')
plt.ylabel('Bitki Boyu (cm)')
plt.grid(True, alpha=0.3)
plt.tight_layout()
plt.show()

# 13. SONUÃ‡ GÃ–RSELLEÅTÄ°RME (step 1 iÃ§in)
# plt.figure(figsize=(15, 6))
# plt.plot(Y_test_inv[100:300], label='GerÃ§ek', color='black', linewidth=2)
# plt.plot(y_pred_inv[100:300], label='LSTM', alpha=0.8)
# plt.plot(y_rnn_pred_inv[100:300], label='RNN', alpha=0.8)
# plt.plot(y_elm_pred_inv[100:300], label='ELM', alpha=0.8)
# plt.legend()
# plt.title(f'LSTM, RNN, ELM ile Bitki Boyu Tahmini (Window Size: {time_steps})')
# plt.xlabel('Zaman')
# plt.ylabel('Bitki Boyu (cm)')
# plt.grid(True, alpha=0.3)
# plt.tight_layout()
# plt.show()

# plt.figure(figsize=(15, 6))
# plt.plot(Y_test_inv[152:165], label='GerÃ§ek', color='black', linewidth=2)
# plt.plot(y_pred_inv[152:165], label='LSTM', alpha=0.8)
# plt.plot(y_rnn_pred_inv[152:165], label='RNN', alpha=0.8)
# plt.plot(y_elm_pred_inv[152:165], label='ELM', alpha=0.8)
# plt.legend()
# plt.title(f'LSTM, RNN, ELM ile Bitki Boyu Tahmini (Window Size: {time_steps})')
# plt.xlabel('Zaman')
# plt.ylabel('Bitki Boyu (cm)')
# plt.grid(True, alpha=0.3)
# plt.tight_layout()
# plt.show()

# Model performans karÅŸÄ±laÅŸtÄ±rma grafiÄŸi
plt.figure(figsize=(12, 4))

plt.subplot(1, 3, 1)
plt.bar(['LSTM', 'RNN', 'ELM'], [mae, mae_rnn, mae_elm], color=['blue', 'orange', 'green'])
plt.title('MAE KarÅŸÄ±laÅŸtÄ±rmasÄ±')
plt.ylabel('MAE')

plt.subplot(1, 3, 2)
plt.bar(['LSTM', 'RNN', 'ELM'], [rmse, rmse_rnn, rmse_elm], color=['blue', 'orange', 'green'])
plt.title('RMSE KarÅŸÄ±laÅŸtÄ±rmasÄ±')
plt.ylabel('RMSE')

plt.subplot(1, 3, 3)
plt.bar(['LSTM', 'RNN', 'ELM'], [r_squared, r2_rnn, r2_elm], color=['blue', 'orange', 'green'])
plt.title('RÂ² KarÅŸÄ±laÅŸtÄ±rmasÄ±')
plt.ylabel('RÂ²')

plt.tight_layout()
plt.show()

# --- Tahmin edilen vs GerÃ§ek scatter plotlarÄ± (tÃ¼m modeller) ---
fig, axes = plt.subplots(1, 3, figsize=(18, 6))

# LSTM scatter plot
axes[0].scatter(Y_test_inv, y_pred_inv, alpha=0.5, label='LSTM', color='blue')
axes[0].plot([Y_test_inv.min(), Y_test_inv.max()], [Y_test_inv.min(), Y_test_inv.max()], 'k--', lw=2)
axes[0].set_xlabel('GerÃ§ek DeÄŸer')
axes[0].set_ylabel('Tahmin (LSTM)')
axes[0].set_title(f'LSTM: GerÃ§ek vs Tahmin (RÂ²={r_squared:.3f})')
axes[0].legend()
axes[0].grid(True, alpha=0.3)

# RNN scatter plot
axes[1].scatter(Y_test_inv, y_rnn_pred_inv, alpha=0.5, label='RNN', color='orange')
axes[1].plot([Y_test_inv.min(), Y_test_inv.max()], [Y_test_inv.min(), Y_test_inv.max()], 'k--', lw=2)
axes[1].set_xlabel('GerÃ§ek DeÄŸer')
axes[1].set_ylabel('Tahmin (RNN)')
axes[1].set_title(f'RNN: GerÃ§ek vs Tahmin (RÂ²={r2_rnn:.3f})')
axes[1].legend()
axes[1].grid(True, alpha=0.3)

# ELM scatter plot
axes[2].scatter(Y_test_inv, y_elm_pred_inv, alpha=0.5, label='ELM', color='green')
axes[2].plot([Y_test_inv.min(), Y_test_inv.max()], [Y_test_inv.min(), Y_test_inv.max()], 'k--', lw=2)
axes[2].set_xlabel('GerÃ§ek DeÄŸer')
axes[2].set_ylabel('Tahmin (ELM)')
axes[2].set_title(f'ELM: GerÃ§ek vs Tahmin (RÂ²={r2_elm:.3f})')
axes[2].legend()
axes[2].grid(True, alpha=0.3)

plt.tight_layout()
plt.show()

# 10.1. EÄÄ°TÄ°M GEÃ‡MÄ°ÅÄ° GÃ–RSELLEÅTÄ°RME (LOSS GRAFÄ°KLERÄ°)
plt.figure(figsize=(15, 5))

# LSTM Loss GrafiÄŸi
plt.subplot(1, 3, 1)
plt.plot(history.history['loss'], label='Train Loss', color='blue', linewidth=2)
plt.plot(history.history['val_loss'], label='Validation Loss', color='red', linewidth=2)
plt.title('LSTM - Training & Validation Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss (MSE)')
plt.legend()
plt.grid(True, alpha=0.3)

# Early stopping noktasÄ±nÄ± iÅŸaretle
if len(history.history['loss']) < 200:  # Early stopping devreye girdiyse
    plt.axvline(x=len(history.history['loss']), color='orange', linestyle='--', 
                label=f'Early Stop (Epoch {len(history.history["loss"])})')
    plt.legend()

# RNN Loss GrafiÄŸi
plt.subplot(1, 3, 2)
plt.plot(rnn_history.history['loss'], label='Train Loss', color='blue', linewidth=2)
plt.plot(rnn_history.history['val_loss'], label='Validation Loss', color='red', linewidth=2)
plt.title('RNN - Training & Validation Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss (MSE)')
plt.legend()
plt.grid(True, alpha=0.3)

# Early stopping noktasÄ±nÄ± iÅŸaretle
if len(rnn_history.history['loss']) < 200:  # Early stopping devreye girdiyse
    plt.axvline(x=len(rnn_history.history['loss']), color='orange', linestyle='--', 
                label=f'Early Stop (Epoch {len(rnn_history.history["loss"])})')
    plt.legend()


# Loss istatistikleri
print("\nğŸ“ˆ EÄÄ°TÄ°M GEÃ‡MÄ°ÅÄ° Ä°STATÄ°STÄ°KLERÄ°:")
print("="*50)
print(f"LSTM:")
print(f"  â€¢ Toplam epoch: {len(history.history['loss'])}")
print(f"  â€¢ Final train loss: {history.history['loss'][-1]:.6f}")
print(f"  â€¢ Final val loss: {history.history['val_loss'][-1]:.6f}")
print(f"  â€¢ Min val loss: {min(history.history['val_loss']):.6f}")

print(f"\nRNN:")
print(f"  â€¢ Toplam epoch: {len(rnn_history.history['loss'])}")
print(f"  â€¢ Final train loss: {rnn_history.history['loss'][-1]:.6f}")
print(f"  â€¢ Final val loss: {rnn_history.history['val_loss'][-1]:.6f}")
print(f"  â€¢ Min val loss: {min(rnn_history.history['val_loss']):.6f}")

# Overfitting analizi
lstm_overfitting = history.history['val_loss'][-1] - min(history.history['val_loss'])
rnn_overfitting = rnn_history.history['val_loss'][-1] - min(rnn_history.history['val_loss'])

print(f"\nğŸ” OVERFÄ°TTÄ°NG ANALÄ°ZÄ°:")
print(f"LSTM overfitting derecesi: {lstm_overfitting:.6f}")
print(f"RNN overfitting derecesi:  {rnn_overfitting:.6f}")

if lstm_overfitting < rnn_overfitting:
    print("âœ… LSTM daha az overfitting gÃ¶steriyor")
else:
    print("âœ… RNN daha az overfitting gÃ¶steriyor")

#%%
# Ã–zellik Ã¶nemi (Permutation Importance) - LSTM iÃ§in
import copy
feature_names = feature_cols  # Modelde kullanÄ±lan feature sÄ±rasÄ± ile aynÄ± olmalÄ±
base_score_lstm = mean_squared_error(Y_test_inv, y_pred_inv)
base_score_elm = mean_squared_error(Y_test_inv, y_elm_pred_inv)

importances_lstm = []
importances_elm = []

print("ğŸ” Ã–zellik Ã¶nemlerini hesaplÄ±yor...")

for i, fname in enumerate(feature_names):
    # LSTM iÃ§in permutation importance
    X_test_shuffled = copy.deepcopy(X_test_seq)
    flat = X_test_shuffled[:, :, i].flatten()
    np.random.shuffle(flat)
    X_test_shuffled[:, :, i] = flat.reshape(X_test_shuffled[:, :, i].shape)
    y_pred_shuffled = model.predict(X_test_shuffled)
    y_pred_shuffled_inv = scaler_y.inverse_transform(y_pred_shuffled.reshape(-1, 1))
    score_lstm = mean_squared_error(Y_test_inv, y_pred_shuffled_inv)
    importances_lstm.append(score_lstm - base_score_lstm)
    
    # ELM iÃ§in permutation importance
    X_test_flat_shuffled = copy.deepcopy(X_test_flat_scaled)
    # Her time step iÃ§in aynÄ± Ã¶zelliÄŸi karÄ±ÅŸtÄ±r
    for t in range(time_steps):
        feature_idx = t * n_features + i
        if feature_idx < X_test_flat_shuffled.shape[1]:
            np.random.shuffle(X_test_flat_shuffled[:, feature_idx])
    
    y_elm_pred_shuffled = elm_model.predict(X_test_flat_shuffled)
    score_elm = mean_squared_error(Y_test_inv, y_elm_pred_shuffled)
    importances_elm.append(score_elm - base_score_elm)

# Ã–zellik Ã¶nemi gÃ¶rselleÅŸtirmesi
plt.figure(figsize=(15, 6))

plt.subplot(1, 2, 1)
plt.barh(feature_names, importances_lstm, color='blue', alpha=0.7)
plt.title('LSTM - Ã–zellik Ã–nemleri (Permutation)')
plt.xlabel('MSE ArtÄ±ÅŸÄ±')
plt.gca().invert_yaxis()

plt.subplot(1, 2, 2)
plt.barh(feature_names, importances_elm, color='green', alpha=0.7)
plt.title('ELM - Ã–zellik Ã–nemleri (Permutation)')
plt.xlabel('MSE ArtÄ±ÅŸÄ±')
plt.gca().invert_yaxis()

plt.tight_layout()
plt.show()

# Ã–zellik Ã¶nemlerini DataFrame olarak gÃ¶ster
importance_df = pd.DataFrame({
    'Feature': feature_names,
    'LSTM_Importance': importances_lstm,
    'ELM_Importance': importances_elm
})
importance_df = importance_df.sort_values('LSTM_Importance', ascending=False)
print("\nğŸ“Š Ã–ZELLIK Ã–NEMLERÄ° TABLOSU:")
print(importance_df.round(4))


# Bitki boyu ile diÄŸer deÄŸiÅŸkenler arasÄ±nda korelasyon matrisi ve gÃ¶rselleÅŸtirme
corr = df[feature_cols + [target_col]].corr()
print('Korelasyon Matrisi:')
print(corr[target_col].sort_values(ascending=False))

plt.figure(figsize=(8,6))
plt.bar(corr[target_col].index, corr[target_col].values)
plt.title('Bitki Boyu ile Korelasyonlar')
plt.ylabel('Korelasyon (plant_height_cm)')
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

# Scatter plot: Bitki boyu ile diÄŸer deÄŸiÅŸkenler
for col in feature_cols:
    if col == target_col:
        continue
    plt.figure(figsize=(5,4))
    plt.scatter(df[col], df[target_col], alpha=0.5)
    plt.xlabel(col)
    plt.ylabel(target_col)
    plt.title(f'{col} vs {target_col}')
    plt.tight_layout()
    plt.show()


#%%
# ğŸš€ MODEL KAYDETME VE SCALER KAYDETME
import joblib
import json
from datetime import datetime

# Modeli kaydet - H5 formatÄ±nda ve uyumlu ÅŸekilde
model_filename = 'plant_growth_lstm_model.h5'
model.save(model_filename, save_format='h5')
print(f"âœ… LSTM modeli kaydedildi: {model_filename}")

# RNN modelini de kaydet
rnn_filename = 'plant_growth_rnn_model.h5'
rnn_model.save(rnn_filename, save_format='h5')
print(f"âœ… RNN modeli kaydedildi: {rnn_filename}")

# ELM modelini kaydet
elm_filename = 'plant_growth_elm_model.pkl'
joblib.dump(elm_model, elm_filename)
print(f"âœ… ELM modeli kaydedildi: {elm_filename}")

# Scaler'larÄ± kaydet
scaler_x_filename = 'scaler_x.pkl'
scaler_y_filename = 'scaler_y.pkl'
scaler_elm_filename = 'scaler_elm.pkl'

joblib.dump(scaler_X, scaler_x_filename)
joblib.dump(scaler_y, scaler_y_filename)
joblib.dump(scaler_elm, scaler_elm_filename)
print(f"âœ… X scaler kaydedildi: {scaler_x_filename}")
print(f"âœ… Y scaler kaydedildi: {scaler_y_filename}")
print(f"âœ… ELM scaler kaydedildi: {scaler_elm_filename}")

# Model parametrelerini kaydet
model_params = {
    'time_steps': time_steps,
    'n_features': n_features,
    'feature_cols': feature_cols,
    'target_col': target_col,
    'train_test_split_seed': 42,
    'model_performance': {
        'lstm_mae': float(mae),
        'lstm_rmse': float(rmse),
        'lstm_r2': float(r_squared),
        'rnn_mae': float(mae_rnn),
        'rnn_rmse': float(rmse_rnn),
        'rnn_r2': float(r2_rnn),
        'elm_mae': float(mae_elm),
        'elm_rmse': float(rmse_elm),
        'elm_r2': float(r2_elm)
    },
    'training_info': {
        'lstm_training_time_sec': float(lstm_training_time),
        'rnn_training_time_sec': float(rnn_training_time),
        'elm_training_time_sec': float(elm_training_time),
        'lstm_parameters': int(lstm_params),
        'rnn_parameters': int(rnn_params),
        'elm_parameters': int(elm_params)
    },
    'model_architectures': {
        'lstm_layers': ['LSTM(96)', 'LSTM(64)', 'Dropout(0.2)', 'Dense(32)', 'Dense(16)', 'Dense(1)'],
        'rnn_layers': ['SimpleRNN(96)', 'SimpleRNN(64)', 'Dropout(0.2)', 'Dense(32)', 'Dense(16)', 'Dense(1)'],
        'elm_config': {
            'hidden_neurons': 150,
            'activation': 'tanh',
            'regularization': 0.01
        }
    },
    'data_info': {
        'train_sequences': len(X_train_seq),
        'test_sequences': len(X_test_seq),
        'total_features': len(feature_cols)
    },
    'created_date': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
}

# JSON olarak kaydet
with open('model_params.json', 'w') as f:
    json.dump(model_params, f, indent=4)
print(f"âœ… Model parametreleri kaydedildi: model_params.json")

print("\n" + "="*60)
print("ğŸ“ KAYDEDILEN DOSYALAR")
print("="*60)
print(f"1. LSTM Model: {model_filename}")
print(f"2. RNN Model: {rnn_filename}")
print(f"3. ELM Model: {elm_filename}")
print(f"4. X Scaler: {scaler_x_filename}")
print(f"5. Y Scaler: {scaler_y_filename}")
print(f"6. ELM Scaler: {scaler_elm_filename}")
print(f"7. Model Params: model_params.json")
print("\nğŸ¯ Bu dosyalar tahmin iÃ§in kullanÄ±labilir!")

# Final comparison summary
print("\n" + "="*80)
print("ğŸ“ˆ KAPSAMLI MODEL KARÅILAÅTIRMASI")
print("="*80)

# Performans tablosu
print("\nğŸ“Š PERFORMANS METRÄ°KLERÄ°:")
print(comparison_df.round(3).to_string(index=False))

# EÄŸitim zamanÄ± tablosu
training_time_df = pd.DataFrame({
    'Model': ['LSTM', 'RNN', 'ELM'],
    'EÄŸitim SÃ¼resi (sn)': [lstm_training_time, rnn_training_time, elm_training_time],
    'Parametre SayÄ±sÄ±': [lstm_params, rnn_params, elm_params]
})
print(f"\nâ±ï¸ EÄÄ°TÄ°M VERÄ°MLÄ°ÄÄ°:")
print(training_time_df.to_string(index=False))

# En iyi modeli belirle
print(f"\nğŸ† En iyi performans (RMSE): {best_model_name} ({comparison_df.loc[best_model_idx, 'RMSE']:.3f})")

# HÄ±z analizi
fastest_model_idx = training_time_df['EÄŸitim SÃ¼resi (sn)'].idxmin()
fastest_model = training_time_df.loc[fastest_model_idx, 'Model']
print(f"âš¡ En hÄ±zlÄ± eÄŸitim: {fastest_model} ({training_time_df.loc[fastest_model_idx, 'EÄŸitim SÃ¼resi (sn)']:.3f} sn)")

# Verimlilik oranÄ± (performans/zaman)
efficiency_scores = []
for i, model_name in enumerate(['LSTM', 'RNN', 'ELM']):
    r2_val = comparison_df.loc[i, 'RÂ²']
    time_val = training_time_df.loc[i, 'EÄŸitim SÃ¼resi (sn)']
    efficiency = r2_val / time_val if time_val > 0 else 0
    efficiency_scores.append(efficiency)

most_efficient_idx = np.argmax(efficiency_scores)
most_efficient_model = ['LSTM', 'RNN', 'ELM'][most_efficient_idx]
print(f"ğŸ¯ En verimli model (RÂ²/zaman): {most_efficient_model} ({efficiency_scores[most_efficient_idx]:.6f})")

print("\n" + "="*80)
print("ğŸ“ SONUÃ‡ Ã–ZETÄ°")
print("="*80)
print(f"â€¢ En yÃ¼ksek doÄŸruluk: {best_model_name}")
print(f"â€¢ En hÄ±zlÄ± eÄŸitim: {fastest_model}")
print(f"â€¢ En verimli: {most_efficient_model}")
print(f"â€¢ Toplam eÄŸitim verimli: {comparison_df.shape[0]} model karÅŸÄ±laÅŸtÄ±rÄ±ldÄ±")
print(f"â€¢ Veri seti: {len(X_train_seq)} eÄŸitim, {len(X_test_seq)} test sequence")
print("="*80)

# %%
# =============================================================================
# ğŸ§¬ DIFFERENTIAL EVOLUTION Ä°LE Ã‡EVREsel KOÅUL OPTÄ°MÄ°ZASYONU
# =============================================================================

from scipy.optimize import differential_evolution
from tensorflow.keras.models import load_model
import warnings
import json
warnings.filterwarnings('ignore')

class PlantGrowthOptimizer:
    """
    Differential Evolution kullanarak en hÄ±zlÄ± bitki bÃ¼yÃ¼mesini saÄŸlayacak
    Ã§evresel koÅŸullarÄ± bulan optimizasyon sÄ±nÄ±fÄ±.
    """
    
    def __init__(self, model, scaler_x, scaler_y, feature_cols, time_steps=3):
        self.model = model
        self.scaler_x = scaler_x
        self.scaler_y = scaler_y
        self.feature_cols = feature_cols
        self.time_steps = time_steps
        self.n_features = len(feature_cols)
        
        # Parametre sÄ±nÄ±rlarÄ±
        self.param_bounds = {
            'h2o_temp_C': (19.9, 27.1),        # Su sÄ±caklÄ±ÄŸÄ±
            'pH': (5.4, 7.5),                  # pH seviyesi
            'EC': (1.5, 3.9),                  # Elektriksel iletkenlik
            'temp_c': (21.0, 28.0),            # Ortam sÄ±caklÄ±ÄŸÄ±
            'relative_humidity_%': (53.0, 64.0), # Nem oranÄ±
            'dewpoint': (13.0, 17.5),          # Ã‡iy noktasÄ±
            'days_since_first_measurement': (0, 41), # GÃ¼n sayÄ±sÄ±
            'reservoir_size_liters': (75, 150)  # Rezervuar boyutu (75 veya 150 L)
        }
        
        # DE iÃ§in bounds listesi oluÅŸtur
        self.bounds = []
        for col in self.feature_cols:
            if col in self.param_bounds:
                self.bounds.append(self.param_bounds[col])
            else:
                raise ValueError(f"Parametre sÄ±nÄ±rÄ± bulunamadÄ±: {col}")
    
    def create_optimized_sequence(self, params, initial_day=0):
        """
        Verilen parametrelerden bir zaman serisi oluÅŸturur.
        Plant-rep kombinasyonu korunur ve days_since_first_measurement artan ÅŸekilde ayarlanÄ±r.
        """
        sequences = []
        
        # Her time_step iÃ§in parametreleri ayarla
        for t in range(self.time_steps):
            time_point = []
            
            for i, col in enumerate(self.feature_cols):
                if col == 'days_since_first_measurement':
                    # GÃ¼n sayÄ±sÄ± artan ÅŸekilde ayarlanÄ±r
                    day_value = initial_day + t
                    day_value = np.clip(day_value, 
                                      self.param_bounds[col][0], 
                                      self.param_bounds[col][1])
                    time_point.append(day_value)
                elif col == 'reservoir_size_liters':
                    # Rezervuar boyutu kategorik: 75 veya 150
                    reservoir_value = 150 if params[i] > 112.5 else 75
                    time_point.append(reservoir_value)
                else:
                    # DiÄŸer parametreler verilen deÄŸerleri kullanÄ±r
                    time_point.append(params[i])
            
            sequences.append(time_point)
        
        return np.array(sequences)
    
    def objective_function(self, params):
        """
        Optimizasyon iÃ§in amaÃ§ fonksiyonu.
        BÃ¼yÃ¼me hÄ±zÄ±nÄ± maksimize etmek iÃ§in negatif deÄŸer dÃ¶ndÃ¼rÃ¼r.
        """
        try:
            # BaÅŸlangÄ±Ã§ gÃ¼nÃ¼ rastgele seÃ§ (erken dÃ¶nem bÃ¼yÃ¼meyi hedefle)
            initial_day = np.random.randint(0, 15)
            
            # Optimize edilmiÅŸ sekansÄ± oluÅŸtur
            sequence = self.create_optimized_sequence(params, initial_day)
            
            # SekansÄ± model iÃ§in uygun forma getir
            sequence_reshaped = sequence.reshape(1, self.time_steps, self.n_features)
            
            # Ã–lÃ§eklendir
            sequence_flat = sequence_reshaped.reshape(-1, self.n_features)
            sequence_scaled = self.scaler_x.transform(sequence_flat)
            sequence_scaled = sequence_scaled.reshape(1, self.time_steps, self.n_features)
            
            # Model tahmini yap
            predicted_height_scaled = self.model.predict(sequence_scaled, verbose=0)
            predicted_height = self.scaler_y.inverse_transform(predicted_height_scaled)[0, 0]
            
            # BÃ¼yÃ¼me hÄ±zÄ±nÄ± hesapla (boy / gÃ¼n)
            current_day = initial_day + self.time_steps - 1
            if current_day > 0:
                growth_rate = predicted_height / current_day
            else:
                growth_rate = predicted_height
            
            # Negatif deÄŸer dÃ¶ndÃ¼r (minimizasyon problemi olarak Ã§Ã¶zmek iÃ§in)
            return -growth_rate
            
        except Exception as e:
            print(f"Hata: {e}")
            return 1000  # BÃ¼yÃ¼k pozitif deÄŸer (kÃ¶tÃ¼ sonuÃ§)
    
    def optimize_growth_conditions(self, max_iterations=100, seed=42):
        """
        Differential Evolution ile en iyi bÃ¼yÃ¼me koÅŸullarÄ±nÄ± bulur.
        """
        print("ğŸ§¬ Differential Evolution ile optimizasyon baÅŸlÄ±yor...")
        print(f"Parametre sayÄ±sÄ±: {len(self.bounds)}")
        print(f"Maksimum iterasyon: {max_iterations}")
        
        # DE optimizasyonu Ã§alÄ±ÅŸtÄ±r
        result = differential_evolution(
            self.objective_function,
            self.bounds,
            maxiter=max_iterations,
            popsize=15,
            seed=seed,
            atol=1e-3,
            tol=1e-3,
            disp=True,
            workers=1  # Paralel iÅŸleme kapalÄ± (model thread-safe olmayabilir)
        )
        
        return result
    
    def analyze_optimal_conditions(self, optimal_params):
        """
        Bulunan optimal koÅŸullarÄ± analiz eder ve raporlar.
        """
        print("\n" + "="*80)
        print("ğŸ¯ OPTÄ°MAL Ã‡EVREsel KOÅULLAR")
        print("="*80)
        
        # Optimal parametreleri dÃ¼zenle
        optimized_conditions = {}
        for i, col in enumerate(self.feature_cols):
            if col == 'reservoir_size_liters':
                # Rezervuar boyutu kategorik
                reservoir_value = 150 if optimal_params[i] > 112.5 else 75
                optimized_conditions[col] = reservoir_value
            else:
                optimized_conditions[col] = optimal_params[i]
        
        # SonuÃ§larÄ± yazdÄ±r
        for param, value in optimized_conditions.items():
            bounds = self.param_bounds[param]
            print(f"{param:<30}: {value:>8.2f} (SÄ±nÄ±r: {bounds[0]:.1f}-{bounds[1]:.1f})")
        
        # FarklÄ± baÅŸlangÄ±Ã§ gÃ¼nleri iÃ§in tahmin yap
        print(f"\nğŸ“ˆ OPTÄ°MAL KOÅULLARDA TAHMIN EDÄ°LEN BÃœYÃœME:")
        print("-" * 60)
        
        growth_predictions = []
        for initial_day in [0, 5, 10, 15, 20]:
            sequence = self.create_optimized_sequence(optimal_params, initial_day)
            sequence_reshaped = sequence.reshape(1, self.time_steps, self.n_features)
            
            # Ã–lÃ§eklendir ve tahmin yap
            sequence_flat = sequence_reshaped.reshape(-1, self.n_features)
            sequence_scaled = self.scaler_x.transform(sequence_flat)
            sequence_scaled = sequence_scaled.reshape(1, self.time_steps, self.n_features)
            
            predicted_height_scaled = self.model.predict(sequence_scaled, verbose=0)
            predicted_height = self.scaler_y.inverse_transform(predicted_height_scaled)[0, 0]
            
            current_day = initial_day + self.time_steps - 1
            growth_rate = predicted_height / current_day if current_day > 0 else predicted_height
            
            growth_predictions.append({
                'start_day': initial_day,
                'end_day': current_day,
                'predicted_height': predicted_height,
                'growth_rate': growth_rate
            })
            
            print(f"GÃ¼n {initial_day:2d}-{current_day:2d}: {predicted_height:6.2f} cm "
                  f"(HÄ±z: {growth_rate:5.2f} cm/gÃ¼n)")
        
        return optimized_conditions, growth_predictions
    
    def compare_with_baseline(self, optimal_params, baseline_params=None):
        """
        Optimal koÅŸullarÄ± baseline (ortalama) koÅŸullarla karÅŸÄ±laÅŸtÄ±rÄ±r.
        """
        if baseline_params is None:
            # Ortalama deÄŸerleri baseline olarak kullan
            baseline_params = []
            for col in self.feature_cols:
                bounds = self.param_bounds[col]
                avg_val = (bounds[0] + bounds[1]) / 2
                baseline_params.append(avg_val)
        
        print(f"\nâš–ï¸ BASELINE vs OPTÄ°MAL KARÅILAÅTIRMA:")
        print("-"*60)
        
        # Her iki koÅŸul iÃ§in de tahmin yap
        for condition_name, params in [("Baseline (Ortalama)", baseline_params), 
                                     ("Optimal", optimal_params)]:
            print(f"\n{condition_name}:")
            
            # Parametreleri yazdÄ±r
            for i, col in enumerate(self.feature_cols):
                if col == 'reservoir_size_liters':
                    value = 150 if params[i] > 112.5 else 75
                else:
                    value = params[i]
                print(f"  {col}: {value:.2f}")
            
            # Tahmin yap
            sequence = self.create_optimized_sequence(params, initial_day=5)
            sequence_reshaped = sequence.reshape(1, self.time_steps, self.n_features)
            sequence_flat = sequence_reshaped.reshape(-1, self.n_features)
            sequence_scaled = self.scaler_x.transform(sequence_flat)
            sequence_scaled = sequence_scaled.reshape(1, self.time_steps, self.n_features)
            
            predicted_height_scaled = self.model.predict(sequence_scaled, verbose=0)
            predicted_height = self.scaler_y.inverse_transform(predicted_height_scaled)[0, 0]
            
            current_day = 5 + self.time_steps - 1
            growth_rate = predicted_height / current_day
            
            print(f"  ğŸ“Š Tahmin: {predicted_height:.2f} cm, HÄ±z: {growth_rate:.3f} cm/gÃ¼n")

# =============================================================================
# ğŸš€ OPTÄ°MÄ°ZASYON Ã‡ALIÅTIRMA
# =============================================================================

print("\n" + "="*80)
print("ğŸ§¬ DIFFERENTIAL EVOLUTION OPTÄ°MÄ°ZASYONU BAÅLATIYOR")
print("="*80)

# En iyi modeli kullan (LSTM)
optimizer = PlantGrowthOptimizer(
    model=model,
    scaler_x=scaler_X,
    scaler_y=scaler_y,
    feature_cols=feature_cols,
    time_steps=time_steps
)

# Optimizasyonu Ã§alÄ±ÅŸtÄ±r
print("â³ Optimizasyon sÃ¼reci baÅŸlÄ±yor... (Bu birkaÃ§ dakika sÃ¼rebilir)")
optimization_result = optimizer.optimize_growth_conditions(
    max_iterations=250,  # Daha iyi sonuÃ§lar iÃ§in artÄ±rÄ±ldÄ±
    seed=13
)

# SonuÃ§larÄ± analiz et (baÅŸarÄ±sÄ±z olsa bile sonuÃ§larÄ± deÄŸerlendir)
if optimization_result.success or optimization_result.fun is not None:
    success_status = "âœ… BaÅŸarÄ±lÄ±!" if optimization_result.success else "âš ï¸ Maksimum iterasyona ulaÅŸÄ±ldÄ± (yine de sonuÃ§ var)"
    print(f"\n{success_status}")
    print(f"ğŸ“Š En iyi fitness deÄŸeri: {-optimization_result.fun:.4f} cm/gÃ¼n")
    print(f"ğŸ”„ Toplam iterasyon: {optimization_result.nit}")
    print(f"ğŸ¯ Fonksiyon deÄŸerlendirmesi: {optimization_result.nfev}")
    
    # SONUÃ‡ KALÄ°TESÄ°NÄ° DEÄERLENDÄ°R
    final_fitness = -optimization_result.fun
    print(f"\nğŸ“ˆ SONUÃ‡ DEÄERLENDÄ°RMESÄ°:")
    print(f"Final bÃ¼yÃ¼me deÄŸeri: {final_fitness:.4f} cm/gÃ¼n")
    
    if final_fitness > 15:
        print("ğŸ¯ MÃ¼kemmel sonuÃ§! (>15 cm/gÃ¼n)")
    elif final_fitness > 10:
        print("âœ… Ä°yi sonuÃ§! (10-15 cm/gÃ¼n)")
    elif final_fitness > 5:
        print("ğŸ”¶ Orta sonuÃ§ (5-10 cm/gÃ¼n)")
    else:
        print("ğŸ”» DÃ¼ÅŸÃ¼k sonuÃ§ (<5 cm/gÃ¼n)")
    
    # Son birkaÃ§ iterasyondaki iyileÅŸmeyi kontrol et
    print(f"Son iterasyonlarda duraÄŸanlÄ±k: {'Evet' if optimization_result.nit >= 40 else 'HayÄ±r'}")
    
    # Optimal koÅŸullarÄ± analiz et
    optimal_conditions, growth_predictions = optimizer.analyze_optimal_conditions(
        optimization_result.x
    )
    
    # Baseline ile karÅŸÄ±laÅŸtÄ±r
    optimizer.compare_with_baseline(optimization_result.x)
    
else:
    print(f"\nâŒ Optimizasyon tamamen baÅŸarÄ±sÄ±z: {optimization_result.message}")
#%%
# Optimal koÅŸullarÄ± kaydet
# JSON serialization iÃ§in float32 deÄŸerleri Python float'a dÃ¶nÃ¼ÅŸtÃ¼r
json_compatible_predictions = []
for pred in growth_predictions:
    json_compatible_predictions.append({
        'start_day': int(pred['start_day']),
        'end_day': int(pred['end_day']),
        'predicted_height': float(pred['predicted_height']),
        'growth_rate': float(pred['growth_rate'])
    })

optimal_results = {
    'optimization_success': True,
    'optimal_growth_rate_cm_per_day': float(-optimization_result.fun),
    'iterations': int(optimization_result.nit),
    'function_evaluations': int(optimization_result.nfev),
    'optimal_conditions': {k: float(v) for k, v in optimal_conditions.items()},
    'growth_predictions': json_compatible_predictions,
    'optimization_message': optimization_result.message
}

# JSON'a kaydet
with open('optimum_values.json', 'w') as f:
    json.dump(optimal_results, f, indent=4)
print(f"\nğŸ’¾ Optimal koÅŸullar kaydedildi: optimum_values.json")
#%%
# =============================================================================
# ğŸ“Š OPTÄ°MÄ°ZASYON SONUÃ‡LARINI GÃ–RSELLEÅTÄ°RME
# =============================================================================

if optimization_result.success or optimization_result.fun is not None:
    print("\nğŸ“Š Optimizasyon sonuÃ§larÄ± gÃ¶rselleÅŸtiriliyor...")
    
    # Optimal koÅŸullar grafiÄŸi
    plt.figure(figsize=(15, 10))
    
    # 1. Optimal parametreler
    plt.subplot(2, 2, 1)
    param_names = [col.replace('_', '\n') for col in feature_cols]
    param_values = [optimal_conditions[col] for col in feature_cols]
    colors = plt.cm.viridis(np.linspace(0, 1, len(param_names)))
    
    bars = plt.bar(range(len(param_names)), param_values, color=colors, alpha=0.7)
    plt.xticks(range(len(param_names)), param_names, rotation=45, ha='right')
    plt.title('Optimal Ã‡evresel KoÅŸullar')
    plt.ylabel('DeÄŸer')
    
    # DeÄŸerleri bar'larÄ±n Ã¼stÃ¼ne yaz
    for bar, value in zip(bars, param_values):
        height = bar.get_height()
        plt.text(bar.get_x() + bar.get_width()/2., height + height*0.01,
                f'{value:.1f}', ha='center', va='bottom', fontsize=8)
    
    # 2. BÃ¼yÃ¼me tahminleri
    plt.subplot(2, 2, 2)
    days = [pred['end_day'] for pred in growth_predictions]
    heights = [pred['predicted_height'] for pred in growth_predictions]
    rates = [pred['growth_rate'] for pred in growth_predictions]
    
    plt.plot(days, heights, 'bo-', linewidth=2, markersize=8, label='Tahmin Edilen Boy')
    plt.xlabel('GÃ¼n')
    plt.ylabel('Bitki Boyu (cm)')
    plt.title('Optimal KoÅŸullarda BÃ¼yÃ¼me Tahmini')
    plt.grid(True, alpha=0.3)
    plt.legend()
    
    # 3. BÃ¼yÃ¼me hÄ±zlarÄ±
    plt.subplot(2, 2, 3)
    plt.bar(range(len(days)), rates, color='green', alpha=0.7)
    plt.xticks(range(len(days)), [f'GÃ¼n {d}' for d in days], rotation=45)
    plt.ylabel('BÃ¼yÃ¼me HÄ±zÄ± (cm/gÃ¼n)')
    plt.title('GÃ¼nlÃ¼k BÃ¼yÃ¼me HÄ±zlarÄ±')
    
    # DeÄŸerleri bar'larÄ±n Ã¼stÃ¼ne yaz
    for i, rate in enumerate(rates):
        plt.text(i, rate + rate*0.01, f'{rate:.3f}', 
                ha='center', va='bottom', fontsize=8)
    
    # 4. Parametre sÄ±nÄ±rlarÄ± ile karÅŸÄ±laÅŸtÄ±rma
    plt.subplot(2, 2, 4)
    
    # days_since_first_measurement parametresini hariÃ§ tut
    filtered_feature_cols = [col for col in feature_cols if col != 'days_since_first_measurement']
    filtered_param_names = [col.replace('_', '\n') for col in filtered_feature_cols]
    
    param_indices = range(len(filtered_feature_cols))
    min_bounds = [optimizer.param_bounds[col][0] for col in filtered_feature_cols]
    max_bounds = [optimizer.param_bounds[col][1] for col in filtered_feature_cols]
    optimal_vals = [optimal_conditions[col] for col in filtered_feature_cols]
    
    # SÄ±nÄ±rlarÄ± gÃ¶ster
    plt.fill_between(param_indices, min_bounds, max_bounds, 
                    alpha=0.3, label='SÄ±nÄ±r AralÄ±ÄŸÄ±', color='gray')
    plt.plot(param_indices, optimal_vals, 'ro-', 
            linewidth=2, markersize=8, label='Optimal DeÄŸerler')
    
    plt.xticks(param_indices, filtered_param_names, rotation=45, ha='right')
    plt.ylabel('DeÄŸer')
    plt.title('Optimal DeÄŸerler vs SÄ±nÄ±r AralÄ±klarÄ±\n(Ã‡evresel Parametreler)')
    plt.legend()
    plt.grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.savefig('optimization_Results.png', dpi=300, bbox_inches='tight')
    plt.show()
    
    # Ã–zet istatistikler
    print("\n" + "="*80)
    print("ğŸ“ˆ OPTÄ°MÄ°ZASYON Ã–ZETÄ°")
    print("="*80)
    print(f"ğŸ¯ Maksimum bÃ¼yÃ¼me hÄ±zÄ±: {-optimization_result.fun:.4f} cm/gÃ¼n")
    print(f"ğŸ“Š Ortalama tahmin boy: {np.mean(heights):.2f} cm")
    print(f"ğŸ”„ Optimizasyon sÃ¼resi: {optimization_result.nfev} fonksiyon deÄŸerlendirmesi")
    print(f"âœ… BaÅŸarÄ± durumu: {'BaÅŸarÄ±lÄ±' if optimization_result.success else 'BaÅŸarÄ±sÄ±z'}")
    
    # En kritik parametreleri belirle
    param_ranges = []
    for col in feature_cols:
        bounds = optimizer.param_bounds[col]
        range_size = bounds[1] - bounds[0]
        optimal_val = optimal_conditions[col]
        normalized_pos = (optimal_val - bounds[0]) / range_size
        param_ranges.append((col, normalized_pos, optimal_val))
    
    # En uÃ§ deÄŸerleri gÃ¶ster
    extreme_params = sorted(param_ranges, key=lambda x: abs(x[1] - 0.5), reverse=True)[:3]
    print(f"\nğŸ” EN KRÄ°TÄ°K PARAMETRELER (sÄ±nÄ±r deÄŸerlerine en yakÄ±n):")
    for param, norm_pos, value in extreme_params:
        position = "maksimuma yakÄ±n" if norm_pos > 0.7 else "minimuma yakÄ±n" if norm_pos < 0.3 else "orta deÄŸerde"
        print(f"  {param}: {value:.2f} ({position})")

print("\n" + "="*80)
print("ğŸ‰ OPTÄ°MÄ°ZASYON TAMAMLANDI!")
print("="*80)

# %%
# =============================================================================
# ğŸ“‹ MEVCUT OPTÄ°MÄ°ZASYON SONUCUNU ANALÄ°Z ET
# =============================================================================

print("\n" + "="*80)
print("ğŸ” MEVCUT OPTÄ°MÄ°ZASYON SONUCU ANALÄ°ZÄ°")
print("="*80)

# Optimizasyon sonucunu deÄŸerlendir
if 'optimization_result' in locals() and optimization_result.fun is not None:
    final_fitness = -optimization_result.fun
    
    print(f"ğŸ“Š SONUÃ‡ Ã–ZETÄ°:")
    print(f"  â€¢ En iyi bÃ¼yÃ¼me deÄŸeri: {final_fitness:.4f} cm/gÃ¼n")
    print(f"  â€¢ Ä°terasyon sayÄ±sÄ±: {optimization_result.nit}/100")
    print(f"  â€¢ Fonksiyon deÄŸerlendirmesi: {optimization_result.nfev}")
    print(f"  â€¢ BaÅŸarÄ± durumu: {'âœ… BaÅŸarÄ±lÄ±' if optimization_result.success else 'âš ï¸ Max iterasyon'}")
    
    # Kalite deÄŸerlendirmesi
    print(f"\nğŸ¯ KALÄ°TE DEÄERLENDÄ°RMESÄ°:")
    if final_fitness > 20:
        quality = "ğŸ† MÃ¼kemmel"
        quality_desc = "Ã‡ok yÃ¼ksek bÃ¼yÃ¼me hÄ±zÄ±"
    elif final_fitness > 15:
        quality = "ğŸ¥‡ Ã‡ok Ä°yi"
        quality_desc = "YÃ¼ksek bÃ¼yÃ¼me hÄ±zÄ±"
    elif final_fitness > 10:
        quality = "ğŸ¥ˆ Ä°yi"
        quality_desc = "Orta-yÃ¼ksek bÃ¼yÃ¼me hÄ±zÄ±"
    elif final_fitness > 5:
        quality = "ğŸ¥‰ Orta"
        quality_desc = "Orta bÃ¼yÃ¼me hÄ±zÄ±"
    else:
        quality = "ğŸ”» DÃ¼ÅŸÃ¼k"
        quality_desc = "DÃ¼ÅŸÃ¼k bÃ¼yÃ¼me hÄ±zÄ±"
    
    print(f"  â€¢ Kalite: {quality} ({quality_desc})")
    print(f"  â€¢ Bu deÄŸer, gÃ¼nde {final_fitness:.2f} cm bÃ¼yÃ¼me demektir!")
    
    # HaftalÄ±k/aylÄ±k projeksiyonlar
    weekly_growth = final_fitness * 7
    monthly_growth = final_fitness * 30
    
    print(f"\nğŸ“ˆ PROJEKSÄ°YONLAR:")
    print(f"  â€¢ HaftalÄ±k bÃ¼yÃ¼me: {weekly_growth:.1f} cm/hafta")
    print(f"  â€¢ AylÄ±k bÃ¼yÃ¼me: {monthly_growth:.1f} cm/ay")
    
    # Veri seti ile karÅŸÄ±laÅŸtÄ±rma
    if 'df' in locals():
        actual_heights = df['plant_height_cm'].values
        max_height = actual_heights.max()
        avg_height = actual_heights.mean();
        
        print(f"\nğŸ“Š VERÄ° SETÄ° KARÅILAÅTIRMASI:")
        print(f"  â€¢ Veri setindeki max boy: {max_height:.1f} cm")
        print(f"  â€¢ Veri setindeki ortalama boy: {avg_height:.1f} cm")
        print(f"  â€¢ Optimize edilmiÅŸ gÃ¼nlÃ¼k bÃ¼yÃ¼me: {final_fitness:.2f} cm/gÃ¼n")
        
        # Bu hÄ±zla ne kadar sÃ¼rede max boy'a ulaÅŸabiliriz
        days_to_max = max_height / final_fitness
        print(f"  â€¢ Bu hÄ±zla {max_height:.1f} cm'e ulaÅŸma sÃ¼resi: {days_to_max:.1f} gÃ¼n")
    
    # Convergence analizi
    print(f"\nğŸ”„ KONVERJANS ANALÄ°ZÄ°:")
    if optimization_result.nit >= 90:
        print(f"  â€¢ âš ï¸ Optimizasyon maksimum iterasyona yakÄ±n durdu")
        print(f"  â€¢ ğŸ’¡ Daha fazla iterasyon ile daha iyi sonuÃ§ alÄ±nabilir")
    elif optimization_result.nit < 30:
        print(f"  â€¢ âœ… HÄ±zlÄ± konverjans - optimal Ã§Ã¶zÃ¼m bulundu")
    else:
        print(f"  â€¢ âœ… Normal konverjans sÃ¼reci")
    
    # =============================================================================
    # ğŸ“Š PARAMETRÄ°K ANALÄ°Z GRAFÄ°KLERÄ°
    # =============================================================================
    
    print("\nğŸ“Š Parametrik analiz grafikleri oluÅŸturuluyor...")
    
    # Optimal deÄŸerleri al
    opt_h2o_temp = optimal_conditions['h2o_temp_C']
    opt_ph = optimal_conditions['pH']
    opt_ec = optimal_conditions['EC']
    opt_temp_c = optimal_conditions['temp_c']
    opt_rh = optimal_conditions['relative_humidity_%']
    opt_dewpoint = optimal_conditions['dewpoint']
    
    # Parametrik analiz iÃ§in fonksiyon
    def evaluate_growth(params):
        """Verilen parametreler iÃ§in bÃ¼yÃ¼me deÄŸerini hesaplar"""
        return -optimizer.objective_function(params)
    
    # Bounds'larÄ± al
    bounds = optimizer.bounds
    
    fig, axes = plt.subplots(2, 3, figsize=(18, 10))
    
    # Su SÄ±caklÄ±ÄŸÄ± etkisi
    temps = np.linspace(bounds[0][0], bounds[0][1], 30)
    temp_growth = [-optimizer.objective_function([t, opt_ph, opt_ec, opt_temp_c, opt_rh, opt_dewpoint, 10, 150]) for t in temps]
    axes[0,0].plot(temps, temp_growth)
    axes[0,0].set_title('Su SÄ±caklÄ±ÄŸÄ± Etkisi')
    axes[0,0].set_xlabel('Su SÄ±caklÄ±ÄŸÄ± (Â°C)')
    axes[0,0].set_ylabel('Tahmini Bitki Boyu (cm)')
    axes[0,0].axvline(opt_h2o_temp, color='r', linestyle='--', label=f'Optimum: {opt_h2o_temp:.2f}')
    axes[0,0].legend()
    
    # pH etkisi
    phs = np.linspace(bounds[1][0], bounds[1][1], 30)
    ph_growth = [-optimizer.objective_function([opt_h2o_temp, p, opt_ec, opt_temp_c, opt_rh, opt_dewpoint, 10, 150]) for p in phs]
    axes[0,1].plot(phs, ph_growth)
    axes[0,1].set_title('pH Etkisi')
    axes[0,1].set_xlabel('pH')
    axes[0,1].axvline(opt_ph, color='r', linestyle='--', label=f'Optimum: {opt_ph:.2f}')
    axes[0,1].legend()
    
    # EC etkisi
    ecs = np.linspace(bounds[2][0], bounds[2][1], 30)
    ec_growth = [-optimizer.objective_function([opt_h2o_temp, opt_ph, e, opt_temp_c, opt_rh, opt_dewpoint, 10, 150]) for e in ecs]
    axes[0,2].plot(ecs, ec_growth)
    axes[0,2].set_title('EC Etkisi')
    axes[0,2].set_xlabel('EC (mS/cm)')
    axes[0,2].axvline(opt_ec, color='r', linestyle='--', label=f'Optimum: {opt_ec:.2f}')
    axes[0,2].legend()
    
    # Ortam SÄ±caklÄ±ÄŸÄ± etkisi
    temp_c_values = np.linspace(bounds[3][0], bounds[3][1], 30)
    temp_c_growth = [-optimizer.objective_function([opt_h2o_temp, opt_ph, opt_ec, t, opt_rh, opt_dewpoint, 10, 150]) for t in temp_c_values]
    axes[1,0].plot(temp_c_values, temp_c_growth)
    axes[1,0].set_title('Ortam SÄ±caklÄ±ÄŸÄ± Etkisi')
    axes[1,0].set_xlabel('Ortam SÄ±caklÄ±ÄŸÄ± (Â°C)')
    axes[1,0].set_ylabel('Tahmini Bitki Boyu (cm)')
    axes[1,0].axvline(opt_temp_c, color='r', linestyle='--', label=f'Optimum: {opt_temp_c:.2f}')
    axes[1,0].legend()
    
    # BaÄŸÄ±l Nem etkisi
    rel_humidities = np.linspace(bounds[4][0], bounds[4][1], 30)
    humidity_growth = [-optimizer.objective_function([opt_h2o_temp, opt_ph, opt_ec, opt_temp_c, h, opt_dewpoint, 10, 150]) for h in rel_humidities]
    axes[1,1].plot(rel_humidities, humidity_growth)
    axes[1,1].set_title('BaÄŸÄ±l Nem Etkisi')
    axes[1,1].set_xlabel('BaÄŸÄ±l Nem (%)')
    axes[1,1].axvline(opt_rh, color='r', linestyle='--', label=f'Optimum: {opt_rh:.2f}')
    axes[1,1].legend()
    
    # Ã‡iÄŸ NoktasÄ± etkisi
    dewpoints = np.linspace(bounds[5][0], bounds[5][1], 30)
    dewpoint_growth = [-optimizer.objective_function([opt_h2o_temp, opt_ph, opt_ec, opt_temp_c, opt_rh, d, 10, 150]) for d in dewpoints]
    axes[1,2].plot(dewpoints, dewpoint_growth)
    axes[1,2].set_title('Ã‡iÄŸ NoktasÄ± Etkisi')
    axes[1,2].set_xlabel('Ã‡iÄŸ NoktasÄ± (Â°C)')
    axes[1,2].axvline(opt_dewpoint, color='r', linestyle='--', label=f'Optimum: {opt_dewpoint:.2f}')
    axes[1,2].legend()
    
    plt.tight_layout()
    plt.show()
    
else:
    print("âŒ Optimizasyon sonucu bulunamadÄ±!")

print("="*80) 
# %%
